{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prostate-brand",
   "metadata": {},
   "source": [
    "# Collect metadata from institutions\n",
    "\n",
    "This is to form a comparison dataset for looking at items associated with universities not yet using Figshare.\n",
    "\n",
    "The assumption is that these records go through some type of vetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "happy-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import json as json\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "united-nashville",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of Institution ids (283-Uni of Cape Town,21-Monash,54-sheffield,898-4tu,797-u Az)\n",
    "INST_LIST = [283,21,54,898,797]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "blocked-frost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 records collected\n"
     ]
    }
   ],
   "source": [
    "#Get 50 Figures from each institution\n",
    "figures = []\n",
    "\n",
    "for i in INST_LIST:\n",
    "    query = '{\"item_type\":1,\"institution\": ' + str(i) + ',\"page\": 1, \"page_size\": 50}' #add more using a comma\n",
    "    y = json.loads(query) #Figshare API requires json paramaters\n",
    "    response = requests.post('https://api.figshare.com/v2/articles/search', params=y)\n",
    "    j=json.loads(response.text) #parse the json into a list named j\n",
    "    figures.extend(j)\n",
    "    #for x in j:\n",
    "    #    figures.append(x) #Above creates a list. So append each record from that list to the master list\n",
    "    \n",
    "print(len(figures),'records collected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "victorian-zoning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 records collected\n"
     ]
    }
   ],
   "source": [
    "#Get 50 Media from each institution\n",
    "media = []\n",
    "\n",
    "for i in INST_LIST:\n",
    "    query = '{\"item_type\":2,\"institution\": ' + str(i) + ',\"page\": 1, \"page_size\": 50}' #add more using a comma\n",
    "    y = json.loads(query) #Figshare API requires json paramaters\n",
    "    response = requests.post('https://api.figshare.com/v2/articles/search', params=y)\n",
    "    j=json.loads(response.text) #parse the json into a list named j\n",
    "    media.extend(j)\n",
    "    \n",
    "print(len(media),'records collected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "applied-spine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 records collected\n"
     ]
    }
   ],
   "source": [
    "#Get 50 Datasets from each institution\n",
    "datasets = []\n",
    "\n",
    "for i in INST_LIST:\n",
    "    query = '{\"item_type\":3,\"institution\": ' + str(i) + ',\"page\": 1, \"page_size\": 50}' #add more using a comma\n",
    "    y = json.loads(query) #Figshare API requires json paramaters\n",
    "    response = requests.post('https://api.figshare.com/v2/articles/search', params=y)\n",
    "    j=json.loads(response.text) #parse the json into a list named j\n",
    "    datasets.extend(j)\n",
    "    \n",
    "print(len(datasets),'records collected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "intended-columbus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I don't think this works same as the next one\n",
    "sampleTest = []\n",
    "sampleTest = figures + media + datasets\n",
    "len(sampleTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "wooden-mouse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = figures\n",
    "sample.extend(media)\n",
    "sample.extend(datasets)\n",
    "\n",
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "compliant-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Master File\n",
    "with open('raw-inst-basic-metadata.json', \"w\") as write_file:\n",
    "    json.dump(sample, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "expected-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe from the JSON formatted data\n",
    "df = pd.DataFrame(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save a file of all the metadata\n",
    "#save_file = df.to_excel(\"xxxxxxxxx.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open up the same file for reading\n",
    "with open(\"raw-inst-basic-metadata.json\", \"r\", encoding='utf8') as read_file: #Replace this with the filename of your choice\n",
    "    sample = json.load(read_file)\n",
    "\n",
    "print(len(sample),\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-attitude",
   "metadata": {},
   "source": [
    "# This is where I left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "inappropriate-wages",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-139d66fd08ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0marticle_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0marticle_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticle_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "#Create list of ids\n",
    "#article_ids = [item['id'] for item in sample]\n",
    "article_ids = []\n",
    "for item in sample:\n",
    "    article_ids.append(item['id'])\n",
    "print(len(article_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a csv file, use an API to gather data, reopen the csv as a dataframe\n",
    "\n",
    "\n",
    "#This function deals with multiply nested json elements in the csv write line below\n",
    "#https://stackoverflow.com/questions/43491287/elegant-way-to-check-if-a-nested-key-exists-in-a-python-dict\n",
    "def exists(obj, chain):\n",
    "    _key = chain.pop(0)\n",
    "    if _key in obj:\n",
    "        return exists(obj[_key], chain) if chain else obj[_key]\n",
    "\n",
    "#Create csv file\n",
    "metadata=open('institution-sample-full-metadata'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv', 'w', encoding='utf-8', newline='')\n",
    "#Write header row to csv\n",
    "csv.writer(metadata).writerow(['id','description','is_embargoed','funding_list','is_metadata_record','published_date','resource_doi','count_categories','count_references','count_tags'])\n",
    "       \n",
    "                      \n",
    "              \n",
    "for l in sampleid:\n",
    "    s=requests.get('https://api.figshare.com/v2/articles/'+l)\n",
    "    r=json.loads(s.text)\n",
    "    \n",
    "    #write the values to the csv file. Dates in json files are seconds from jan 1 1970 so datetime.datetime.fromtimestamp converts\n",
    "    csv.writer(metadata).writerow([\n",
    "        r['id'],\n",
    "        r.get('description'), #For any of these .get(), adding \",'N/A'\" will fill the null cells with 'N/A'. However, metadata assessment counts non nulls\n",
    "        r.get('is_embargoed'),\n",
    "        exists(r,['funding_list']) if exists(r,['funding_list']) !=None else 0,\n",
    "        r.get('is_metadata_record'),\n",
    "        r.get('published_date'),\n",
    "        exists(r,['resource_doi']) if exists(r,['resource_doi']) !=None else 0,\n",
    "        len(exists(r,['categories'])) if exists(r,['categories'])!=None else 0,\n",
    "        len(exists(r,['references'])) if exists(r,['references'])!=None else 0,\n",
    "        len(exists(r,['tags'])) if exists(r,['tags'])!=None else 0]) #write one line to csv file\n",
    "    \n",
    "metadata.close() #Close the output file, release all locks\n",
    "\n",
    "#Open up the same file as a dataframe. Encode cp1252 avoids a utf8 error.\n",
    "dffull = pd.read_csv('institution-sample-full-metadata'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv',encoding='utf8')\n",
    "\n",
    "print('The resulting dataframe has',len(dffull),' rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deal with funders \n",
    "funderMaster = [] #funder name might be duplicated across multiple grants for an item. Create a dictionary to deduplicate later\n",
    "for f in sample['funding_list']:\n",
    "    entry = {\"id\":article_id, \"funder_name\":f['funder_name']}\n",
    "    funderMaster.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-miami",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save funder File\n",
    "with open('funder-name.json', \"w\") as write_file:\n",
    "    json.dump(funderMaster, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-planner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
