{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "thorough-dictionary",
   "metadata": {},
   "source": [
    "## This retrieves all metadata including for private or fully embargoed items in all accounts\n",
    "For demonstration only and would need slight tweaking to give you exactly the metadata you want.\n",
    "This does not retrieve metadata for collections or projects.\n",
    "\n",
    "The end result is a spreadsheet of metadata with the several things added or modified:\n",
    "1. The item owners name and email is added\n",
    "2. The group the item belongs to is added\n",
    "3. The author names are formatted to be more readable and ORCID is included\n",
    "4. The dates are split out into their own columns\n",
    "5. Any custom fields are separated out into their own columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-williams",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e37a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-lending",
   "metadata": {},
   "source": [
    "## Set token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "continued-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the base URL\n",
    "BASE_URL = 'https://api.figshare.com/v2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-blowing",
   "metadata": {},
   "source": [
    "## Retrieve Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "international-arizona",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered 20 etd records\n"
     ]
    }
   ],
   "source": [
    "etd_records = []\n",
    "for i in range(1,3):\n",
    "    query = '{\"institution\":231, \"group\":18614, \"page_size\":10, \"page\":'+ str(i) + '}'\n",
    "    y = json.loads(query) #convert to json\n",
    "    records = json.loads(requests.post(BASE_URL + '/articles/search', params=y).content)\n",
    "    etd_records.extend(records)\n",
    "\n",
    "print('Gathered',len(etd_records),'etd records')\n",
    "\n",
    "#Gather basic metadata for items (articles) that meet your search criteria\n",
    " #Can used advanced syntax for 'search_for'\n",
    "\n",
    "#y = json.loads(query) #Figshare API requires json paramaters\n",
    "#articles = json.loads(requests.post(BASE_URL + \"/articles/search\", params=y).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-official",
   "metadata": {},
   "source": [
    "## Collect record metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "expanded-emphasis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full metadata for 20 ETD records retrieved\n"
     ]
    }
   ],
   "source": [
    "#For each id in the list, retrieve all the metadata for the article by visiting the Figshare article API endpoint \n",
    "#Admin token does not need to impersonate\n",
    "#This may take a while if there are a lot of items. ~1.5 seconds per item\n",
    "\n",
    "\n",
    "#Gather and format each record:\n",
    "full_etd_records = []\n",
    "for item in etd_records: \n",
    "    s=requests.get(BASE_URL + '/articles/' + str(item['id']))\n",
    "    metadata=json.loads(s.text)\n",
    "    full_etd_records.append(metadata)\n",
    "\n",
    "print('Full metadata for',len(full_etd_records),'ETD records retrieved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "beneficial-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIONAL: save the json. Change the file name to represent the list of ids you used.\n",
    "with open('full_etd_records-'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.json', 'w') as f:\n",
    "    json.dump(full_records, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2149a183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe from the JSON formatted data\n",
    "df = pd.DataFrame(full_etd_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-webcam",
   "metadata": {},
   "source": [
    "## Gather Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "passive-fiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The resulting dataframe has 4 rows and they were merged to the metadata dataframe\n"
     ]
    }
   ],
   "source": [
    "#Create a list of all the article ids\n",
    "article_ids = [item['id'] for item in full_etd_records]           \n",
    "\n",
    "#Gather views and downloads\n",
    "stat_file = []            \n",
    "for l in article_ids:\n",
    "    s=requests.get('https://stats.figshare.com/total/views/article/'+ str(l))\n",
    "    r=json.loads(s.text)\n",
    "    t=requests.get('https://stats.figshare.com/total/downloads/article/'+ str(l))\n",
    "    q=json.loads(t.text)\n",
    "    stats = '{\"id\":'+str(l)+',\"views\":'+str(r.get('totals'))+',\"downloads\":'+str(q.get('totals'))+'}'\n",
    "    stats_json = json.loads(stats)\n",
    "    stat_file.append(stats_json)\n",
    "\n",
    "#Create a dataframe from the JSON formatted data\n",
    "dfstats = pd.DataFrame(stat_file)\n",
    "\n",
    "df = df.merge(dfstats, how='inner', on='id')\n",
    "\n",
    "print('The resulting dataframe has',len(dfstats),'rows and they were merged to the metadata dataframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-valentine",
   "metadata": {},
   "source": [
    "## Format the spreadsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-recipient",
   "metadata": {},
   "source": [
    "### Split out the dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "thick-preliminary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates split out and merged\n"
     ]
    }
   ],
   "source": [
    "#The dates are all contained within one column called 'timeline'. Flatten that column and associate the values\n",
    "#with the proper article id in a new dataframe\n",
    "\n",
    "temp_date_list = []\n",
    "\n",
    "for item in full_etd_records:\n",
    "    dateitem = item['timeline']\n",
    "    dateitem['id'] = item['id']\n",
    "    temp_date_list.append(dateitem)\n",
    "\n",
    "df_dates = pd.json_normalize(\n",
    "    temp_date_list \n",
    ")\n",
    "\n",
    "#Merge the dataframes\n",
    "df_formatted = df.merge(df_dates, how='outer', on='id')\n",
    "\n",
    "print(\"Dates split out and merged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-nation",
   "metadata": {},
   "source": [
    "### Split out custom fields\n",
    "This creates new columns for each custom field.\n",
    "\n",
    "If different groups have different custom metadata, check the output carefully to make sure things mapped properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "alleged-cartoon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom fields split out and merged\n"
     ]
    }
   ],
   "source": [
    "#The custom fields are all contained within one column called 'custom_fields'. Flatten that column and associate the values\n",
    "#with the proper article id in a new dataframe\n",
    "custom = pd.json_normalize(\n",
    "    full_etd_records, \n",
    "    record_path =['custom_fields'], \n",
    "    meta=['id']\n",
    ")\n",
    "#This reshapes the data so that metadata field names are columns and each row is an id.\n",
    "custom = custom.pivot(index=\"id\", columns=\"name\", values=\"value\")\n",
    "\n",
    "#Merge the dataframes so that all the custom fields are visible along with all the other metadata\n",
    "df_formatted = df_formatted.merge(custom, how='outer', on='id') #Outer merge keeps records that have no custom metadata.\n",
    "\n",
    "print(\"Custom fields split out and merged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-adoption",
   "metadata": {},
   "source": [
    "## Save the spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "robust-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save a CSV file of all the metadata. Change the file name if necessary to match dates.\n",
    "save_file = df_formatted.to_csv('etd-records-'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "composite-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or save an Excel file of all the metadata. Change the file name if necessary to match dates.\n",
    "save_file = df_formatted.to_excel('etd-records-'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
