{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "thorough-dictionary",
   "metadata": {},
   "source": [
    "## This retrieves metadata items in review\n",
    "You can modify this to give you exactly the metadata you want.\n",
    "This does not retrieve metadata for collections or projects.\n",
    "\n",
    "The end result is a spreadsheet of metadata with several things added or modified:\n",
    "1. The item owners name and email is added\n",
    "2. The group the item belongs to is added\n",
    "3. The author names are formatted to be more readable and ORCID is included\n",
    "4. The dates are split out into their own columns\n",
    "5. Any custom fields are separated out into their own columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-williams",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e37a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-lending",
   "metadata": {},
   "source": [
    "## Set token, admin id, and base URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IF RUNNING THIS IN GOOGLE COLAB ENTER TOKEN BELOW\n",
    "\n",
    "TOKEN = 'ENTER TOKEN BETWEEN QUOTES' #example: 'dkd8rskjdkfiwi49hgkw...'\n",
    "\n",
    "#Set the token in the header.\n",
    "api_call_headers = {'Authorization': 'token ' + TOKEN} #example: {'Authorization': 'token dkd8rskjdkfiwi49hgkw...'}\n",
    "\n",
    "#Set the base URL\n",
    "BASE_URL = 'https://api.figshare.com/v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IF RUNNING THIS ON YOUR MACHINE AND TOKEN IS SAVED IN A TEXT FILE\n",
    "#Set the token in the header.\n",
    "text_file = open(\"../../../faber-andrew-key.txt\", \"r\") #Paste your token in a text file and save it where this notebook is\n",
    "TOKEN = text_file.read()\n",
    "TOKEN.strip() #removes any hidden spaces\n",
    "text_file.close()\n",
    "\n",
    "\n",
    "api_call_headers = {'Authorization': 'token ' + TOKEN}\n",
    "\n",
    "#Set the base URL\n",
    "BASE_URL = 'https://api.figshare.com/v2' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-blowing",
   "metadata": {},
   "source": [
    "## Retrieve Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather all private records (make sure your token is for a top level admin account)\n",
    "pending_records = []\n",
    "\n",
    "records = json.loads(requests.get(BASE_URL + '/account/institution/reviews?status=pending&limit=1000', headers=api_call_headers).content)\n",
    "pending_records.extend(records)\n",
    "\n",
    "print('Gathered',len(pending_records),'records in for review')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-official",
   "metadata": {},
   "source": [
    "## Collect full metadata\n",
    "Using the list you have of basic metadata with owner id and owner name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each id in the list, retrieve all the metadata for the article by visiting the Figshare article API endpoint \n",
    "#Admin token does not need to impersonate\n",
    "#This may take a while if there are a lot of items. ~1.5 seconds per item\n",
    "\n",
    "#First get a list of all the users. Email and name will be extracted based on account id later\n",
    "users = []\n",
    "for i in range(1,10):\n",
    "    usr = json.loads(requests.get(BASE_URL + '/account/institution/accounts?page_size=1000&page={}'.format(i), headers=api_call_headers).content)\n",
    "    users.extend(usr)\n",
    "\n",
    "#Then gather and format each record:\n",
    "full_records = []\n",
    "for item in pending_records: \n",
    "    s=requests.get(BASE_URL + '/account/articles/' + str(item['article_id']), headers=api_call_headers)\n",
    "    metadata=json.loads(s.text)\n",
    "    counter = 0\n",
    "    author_list = \"\"\n",
    "    author_count = len(metadata['authors'])\n",
    "    for name in metadata['authors']: #Format author list to be readable\n",
    "        if counter == 0:\n",
    "            author_list = author_list + name['full_name'] + ' (ORCID: ' + name['orcid_id'] + ')'\n",
    "            counter += 1\n",
    "        elif counter < author_count:\n",
    "            author_list = author_list + ' | ' + name['full_name'] + ' (ORCID: ' + name['orcid_id'] + ')'\n",
    "            counter += 1\n",
    "    metadata['author_readable'] = author_list\n",
    "    \n",
    "    for person in users:\n",
    "        if person['id'] == item['account_id']:\n",
    "            metadata['record_owner_name'] = person['first_name'] + ' ' + person['last_name'] #add in user name\n",
    "            metadata['owner_email'] = person['email'] #add user email\n",
    "\n",
    "    full_records.append(metadata)\n",
    "\n",
    "print('Full metadata for',len(full_records),'records retrieved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-productivity",
   "metadata": {},
   "source": [
    "## Create and format a spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2149a183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe from the JSON formatted data\n",
    "df = pd.DataFrame(full_records)\n",
    "\n",
    "#---------------------Make dates readable -----------------------\n",
    "#The dates are all contained within one column called 'timeline'. Flatten that column and associate the values\n",
    "#with the proper article id in a new dataframe\n",
    "\n",
    "temp_date_list = []\n",
    "\n",
    "for item in full_records:\n",
    "    dateitem = item['timeline']\n",
    "    dateitem['id'] = item['id']\n",
    "    temp_date_list.append(dateitem)\n",
    "\n",
    "df_dates = pd.json_normalize(\n",
    "    temp_date_list \n",
    ")\n",
    "\n",
    "#Merge the dataframes\n",
    "df_formatted = df.merge(df_dates, how='outer', on='id')\n",
    "\n",
    "print(\"Dates split out and merged\")\n",
    "\n",
    "#-------------Add Group names -----------------------------\n",
    "\n",
    "#Get list of groups. \n",
    "s=requests.get(BASE_URL + '/account/institution/groups', headers=api_call_headers)\n",
    "groups=json.loads(s.text)\n",
    "\n",
    "#Create a dataframe of groups\n",
    "df_groups = pd.json_normalize(groups)\n",
    "\n",
    "df_groups_parent = df_groups[['id','name']] #Create reference dataframe\n",
    "df_groups = df_groups.rename(columns={'id': 'group_id','name': 'group_name'}) #Rename id col in main dataframe\n",
    "df_groups_parent = df_groups_parent.rename(columns={'name': 'parent_group_name'}) #Rename name col in reference dataframe\n",
    "\n",
    "df_groups = df_groups.sort_values(by=['parent_id'])\n",
    "top_group_id = df_groups.iloc[0]['group_id'] #Store the group id for top group \n",
    "\n",
    "df_groups.loc[df_groups['parent_id'] == 0, 'parent_id'] = top_group_id #For top level group, replace the zero value parent id with top level group id\n",
    "\n",
    "df_groups = df_groups.merge(df_groups_parent, how='inner',left_on=['parent_id'], right_on=['id']) #Add parent group name\n",
    "\n",
    "df_groups = df_groups[['group_id','group_name','parent_group_name']] #Pare down to needed columns\n",
    "\n",
    "\n",
    "#Merge the dataframes \n",
    "df_formatted = df_formatted.merge(df_groups, how='inner', on='group_id') #If you use 'outer' it will include a blank record for each group with no records\n",
    "\n",
    "print(\"Names for\",len(df_groups),\"different groups were added to the metadata records\")\n",
    "\n",
    "#----------------Split out custom fields------------------------\n",
    "\n",
    "#The custom fields are all contained within one column called 'custom_fields'. Flatten that column and associate the values\n",
    "#with the proper article id in a new dataframe\n",
    "custom = pd.json_normalize(\n",
    "    full_records, \n",
    "    record_path =['custom_fields'], \n",
    "    meta=['id']\n",
    ")\n",
    "#This reshapes the data so that metadata field names are columns and each row is an id.\n",
    "custom = custom.pivot(index=\"id\", columns=\"name\", values=\"value\")\n",
    "\n",
    "#Merge the dataframes so that all the custom fields are visible along with all the other metadata\n",
    "df_formatted = df_formatted.merge(custom, how='outer', on='id') #Outer merge keeps records that have no custom metadata.\n",
    "\n",
    "print(\"Custom fields split out and merged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-garden",
   "metadata": {},
   "source": [
    "# If running this in Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-intent",
   "metadata": {},
   "source": [
    "## Save the Spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-transmission",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When you run this cell it will ask you to authenticate so that you can create files to download\n",
    "from google.colab import drive\n",
    "drive.mount('/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "df_formatted.to_csv('records-in-for-review-'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv',encoding='utf-8') #create the CSV\n",
    "files.download('records-in-for-review-'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv') #download to your computer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-frontier",
   "metadata": {},
   "source": [
    "# If you are running this on your own system\n",
    "That is, you downloaded the Jupyter Notebook file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-adoption",
   "metadata": {},
   "source": [
    "## Save the spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save a CSV file of all the metadata. Change the file name if necessary to match dates.\n",
    "save_file = df_formatted.to_csv('records-in-for-review-'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or save an Excel file of all the metadata. Change the file name if necessary to match dates.\n",
    "save_file = df_formatted.to_excel('records-in-for-review-'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-leadership",
   "metadata": {},
   "source": [
    "## Optional: Save the json formatted metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIONAL: save the json. Change the file name to represent the list of ids you used.\n",
    "with open('full_records-'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.json', 'w') as f:\n",
    "    json.dump(full_records, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
