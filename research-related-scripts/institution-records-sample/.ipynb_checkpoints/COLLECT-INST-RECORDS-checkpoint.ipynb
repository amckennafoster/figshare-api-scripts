{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prostate-brand",
   "metadata": {},
   "source": [
    "# Collect metadata from institutions for non-traditional outputs\n",
    "\n",
    "This collects metadata from records in institutional repositories that are using Figshare as the repository platform to create a comparison dataset of non traditional research outputs. \n",
    "\n",
    "The assumption is that these records go through some type of vetting. Five institutions are sampled:\n",
    "- University of Cape Town\n",
    "- Monash University\n",
    "- University of Sheffield\n",
    "- 4TU\n",
    "- University of Arizona\n",
    "- Loughborough\n",
    "- University of Illinois at Chicago\n",
    "\n",
    "50 recent records from the following items types are collected from each institution:\n",
    "- figure\n",
    "- media\n",
    "- dataset\n",
    "- presentations\n",
    "- posters\n",
    "- software\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import json as json\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-nashville",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of Institution ids (283-Uni of Cape Town,21-Monash,54-sheffield,898-4tu,797-u Az)\n",
    "INST_LIST = [283,21,54,898,797,2,693]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get 50 Figures from each institution\n",
    "figures = []\n",
    "\n",
    "for i in INST_LIST:\n",
    "    query = '{\"item_type\":1,\"institution\": ' + str(i) + ',\"page\": 1, \"page_size\": 50}' #add more using a comma\n",
    "    y = json.loads(query) #Figshare API requires json paramaters\n",
    "    response = requests.post('https://api.figshare.com/v2/articles/search', params=y)\n",
    "    j=json.loads(response.text) #parse the json into a list named j\n",
    "    figures.extend(j)\n",
    "    #for x in j:\n",
    "    #    figures.append(x) #Above creates a list. So append each record from that list to the master list\n",
    "    \n",
    "print(len(figures),'records collected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get 50 Media from each institution\n",
    "media = []\n",
    "\n",
    "for i in INST_LIST:\n",
    "    query = '{\"item_type\":2,\"institution\": ' + str(i) + ',\"page\": 1, \"page_size\": 50}' #add more using a comma\n",
    "    y = json.loads(query) #Figshare API requires json paramaters\n",
    "    response = requests.post('https://api.figshare.com/v2/articles/search', params=y)\n",
    "    j=json.loads(response.text) #parse the json into a list named j\n",
    "    media.extend(j)\n",
    "    \n",
    "print(len(media),'records collected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get 50 Datasets from each institution\n",
    "datasets = []\n",
    "\n",
    "for i in INST_LIST:\n",
    "    query = '{\"item_type\":3,\"institution\": ' + str(i) + ',\"page\": 1, \"page_size\": 50}' #add more using a comma\n",
    "    y = json.loads(query) #Figshare API requires json paramaters\n",
    "    response = requests.post('https://api.figshare.com/v2/articles/search', params=y)\n",
    "    j=json.loads(response.text) #parse the json into a list named j\n",
    "    datasets.extend(j)\n",
    "    \n",
    "print(len(datasets),'records collected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get 50 Presentations from each institution\n",
    "presentations = []\n",
    "\n",
    "for i in INST_LIST:\n",
    "    query = '{\"item_type\":7,\"institution\": ' + str(i) + ',\"page\": 1, \"page_size\": 50}' #add more using a comma\n",
    "    y = json.loads(query) #Figshare API requires json paramaters\n",
    "    response = requests.post('https://api.figshare.com/v2/articles/search', params=y)\n",
    "    j=json.loads(response.text) #parse the json into a list named j\n",
    "    presentations.extend(j)\n",
    "    \n",
    "print(len(presentations),'records collected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get 50 Posters from each institution\n",
    "posters = []\n",
    "\n",
    "for i in INST_LIST:\n",
    "    query = '{\"item_type\":5,\"institution\": ' + str(i) + ',\"page\": 1, \"page_size\": 50}' #add more using a comma\n",
    "    y = json.loads(query) #Figshare API requires json paramaters\n",
    "    response = requests.post('https://api.figshare.com/v2/articles/search', params=y)\n",
    "    j=json.loads(response.text) #parse the json into a list named j\n",
    "    posters.extend(j)\n",
    "    \n",
    "print(len(posters),'records collected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get 50 Software from each institution\n",
    "software = []\n",
    "\n",
    "for i in INST_LIST:\n",
    "    query = '{\"item_type\":9,\"institution\": ' + str(i) + ',\"page\": 1, \"page_size\": 50}' #add more using a comma\n",
    "    y = json.loads(query) #Figshare API requires json paramaters\n",
    "    response = requests.post('https://api.figshare.com/v2/articles/search', params=y)\n",
    "    j=json.loads(response.text) #parse the json into a list named j\n",
    "    software.extend(j)\n",
    "    \n",
    "print(len(software),'records collected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-mouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = figures\n",
    "sample.extend(media)\n",
    "sample.extend(datasets)\n",
    "sample.extend(presentations)\n",
    "sample.extend(posters)\n",
    "sample.extend(software)\n",
    "\n",
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Master File\n",
    "with open('raw-inst-basic-metadata.json', \"w\") as write_file:\n",
    "    json.dump(sample, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe from the JSON formatted data\n",
    "df = pd.DataFrame(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save a file of all the metadata\n",
    "#save_file = df.to_excel(\"xxxxxxxxx.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open up the same file for reading\n",
    "with open(\"raw-inst-basic-metadata.json\", \"r\", encoding='utf8') as read_file: #Replace this with the filename of your choice\n",
    "    sample = json.load(read_file)\n",
    "\n",
    "print(len(sample),\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-wages",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of ids\n",
    "#article_ids = [item['id'] for item in sample]\n",
    "article_ids = []\n",
    "for item in sample:\n",
    "    article_ids.append(item['id'])\n",
    "print(len(article_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visit each item and extract the size for each file and collect some publication dates - Comparison Records\n",
    "#use rpartition on '/'\n",
    "\n",
    "def exists(obj, chain):\n",
    "    _key = chain.pop(0)\n",
    "    if _key in obj:\n",
    "        return exists(obj[_key], chain) if chain else obj[_key]\n",
    "\n",
    "#-----------------------------Create csv files---------------------------------------\n",
    "df_author_info=open('institution-sample-full-metadata-authors'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv', 'w', encoding='utf-8', newline='')\n",
    "df_file_info=open('institution-sample-full-metadata-files'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv', 'w', encoding='utf-8', newline='')\n",
    "dffull=open('institution-sample-full-metadata'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv', 'w', encoding='utf-8', newline='')\n",
    "#Write header row to csv\n",
    "csv.writer(df_author_info).writerow(['item_id','author_id','full_name','orcid_id'])\n",
    "csv.writer(df_file_info).writerow(['item_id','file_name','file_size_bytes','link_only'])\n",
    "csv.writer(dffull).writerow(['id','posted_date','doi','title','description','type','categories','funders',\n",
    "                              'count_categories','count_references','count_tags','views','firstOnline','version'])\n",
    "\n",
    "funderMaster = []\n",
    "categoryMaster = [] \n",
    "embargoed = []\n",
    "\n",
    "for i in comp_ids:\n",
    "    #tup = i.rpartition('/') #From end of URL, split string '/' \n",
    "    #article_id = str(tup[2]) #Then select the id from the resulting tuple.\n",
    "    record = json.loads(requests.get('https://api.figshare.com/v2/articles/' + str(i)).content)\n",
    "    views = json.loads(requests.get('https://stats.figshare.com/total/views/article/' + str(i)).content)\n",
    "    #Get publish date, title, categories\n",
    "    #First get a list of category names and funder information from record\n",
    "    cats = []\n",
    "    for c in record['categories']:\n",
    "        cats.append(c['title'])\n",
    "        comp_categoryMaster.append(c['title'])\n",
    "    \n",
    "    funders = [] #funder name might be duplicated across multiple grants for an item. Create a dictionary to deduplicate later\n",
    "    for f in record['funding_list']:\n",
    "        entry = {\"item_id\":i, \"grant_title\":f['title'], \"funder_name\":f['funder_name'], \"postDate\":record['timeline']['posted']}\n",
    "        funders.append(entry)\n",
    "        comp_funderMaster.append(entry)\n",
    "    \n",
    "    #grants = [] #items shouldn't have two of the exact same title listed so just make a list\n",
    "    #for g in record['funding_list']:\n",
    "    #    grants.append(f['title'])\n",
    "    \n",
    "    #Then write to csv\n",
    "    csv.writer(dffull).writerow([\n",
    "                    i,\n",
    "                    record['timeline']['posted'],\n",
    "                    record['doi'],\n",
    "                    record['title'],\n",
    "                    record['description'],\n",
    "                    record['defined_type_name'],\n",
    "                    cats,\n",
    "                    funders,\n",
    "                    len(exists(record,['categories'])) if exists(record,['categories'])!=None else 0, #CHECK THIS\n",
    "                    len(exists(record,['references'])) if exists(record,['references'])!=None else 0,\n",
    "                    len(exists(record,['tags'])) if exists(record,['tags'])!=None else 0,\n",
    "                    views['totals'],\n",
    "                    exists(record['timeline'],['firstOnline']),\n",
    "                    exists(record,['version'])\n",
    "                    ])\n",
    "    \n",
    "  \n",
    "    #Get file names and sizes\n",
    "\n",
    "    if record['is_embargoed'] == 0: #If the record is not embargoed\n",
    "            for z in record['files']:  \n",
    "                csv.writer(df_file_info).writerow([\n",
    "                    i, #item id\n",
    "                    z['name'],\n",
    "                    z['size'],\n",
    "                    z['is_link_only']])\n",
    "    else:\n",
    "        comp_embargoed.append(record['figshare_url']) #if embargoed, add url to a list\n",
    "        \n",
    "    #Get author info\n",
    "\n",
    "    for a in record['authors']:  \n",
    "            csv.writer(df_author_info).writerow([\n",
    "                i, #item id\n",
    "                a['id'], #author id\n",
    "                a['full_name'],\n",
    "                a['orcid_id']])\n",
    "    \n",
    "\n",
    "comp_author_info.close() #Close the output file, release all locks\n",
    "comp_file_info.close() #Close the output file, release all locks\n",
    "dffull.close() #Close the output file, release all locks\n",
    "\n",
    "#Load file just created as a dataframe\n",
    "df_author_info = pd.read_csv('institution-sample-full-metadata-authors'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv')\n",
    "df_file_info = pd.read_csv('institution-sample-full-metadata-files'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv')\n",
    "dffull = pd.read_csv('institution-sample-full-metadata'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv')\n",
    "\n",
    "print(len(dffull),\"records gathered and\",len(df_file_info),\"file info records gathered\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the original metadata records and the item info\n",
    "#first remove the title and doi columns from the second table\n",
    "dffull = comp_item_info_x[['id','posted_date','description','type','categories','funders',\n",
    "                              'count_categories','count_references','count_tags','views','firstOnline','version']].copy()\n",
    "\n",
    "\n",
    "#Merge the basic metadata with the detailed metadata\n",
    "df_combo = df.merge(dffull, how='inner', on='id')\n",
    "print(len(df_combo))\n",
    "\n",
    "#change col name\n",
    "df_combo = df_combo.rename(columns={\"url_public_html\": \"public_url\"})\n",
    "#add needed cols\n",
    "comparison = 'Comparison Records'\n",
    "df_combo['origin'] = comparison\n",
    "df_combo['school'] = \"\"\n",
    "#extract relevant columns\n",
    "df_master = comp_item_info[['id','public_url','posted_date','doi',\n",
    "                                     'title', 'description', 'type','categories','funders',\n",
    "                                    'count_categories','count_references','count_tags', 'origin',\n",
    "                                     'views','firstOnline','version']]\n",
    "\n",
    "\n",
    "#Save a CSV file of all the metadata.\n",
    "save_file = df_master.to_csv('institution-sample-MASTER-metadata-'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv',encoding='utf-8')\n",
    "df_master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the category and funding lists - Comparison Records\n",
    "#convert list to df\n",
    "categorydf = pd.DataFrame(categoryMaster, columns=[\"title\"], index=None)\n",
    "save_file = categorydf.to_csv('institution-sample-categorylist.csv',encoding='utf-8')\n",
    "\n",
    "#save funder json\n",
    "with open('institution-sample-funderlist.json', \"w\") as write_file:\n",
    "    json.dump(funderMaster, write_file)\n",
    "\n",
    "#Flatten funder info and save as csv\n",
    "funderdf = pd.json_normalize(funderMaster)\n",
    "save_file = funderdf.to_csv('institution-sample-funderlist.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-funds",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
