{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "thorough-dictionary",
   "metadata": {},
   "source": [
    "## This retrieves all metadata and statistics for an author - items and collections\n",
    "\n",
    "There are two ways to collect records: by name or by ORCID\n",
    "\n",
    "Note: This is set up to only return records from a given institution. It could be modified to search across all Figshare repositories by removing the institution id query term.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-williams",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e37a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-lending",
   "metadata": {},
   "source": [
    "## Set base URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the base URL\n",
    "BASE_URL = 'https://api.figshare.com/v2'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-blowing",
   "metadata": {},
   "source": [
    "## Retrieve Metadata by Author Name (Note this does not disambiguate people with the same name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-sheet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#author name\n",
    "name = \"ENTER NAME BETWEEN QUOTES\"\n",
    "\n",
    "#Institution id\n",
    "INST_ID = \"ENTER ID HERE BETWEEN QUOTES\" #Example INST_ID = \"658\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve list of private metadata- this is for unpublished and published records.\n",
    "#SET THE PAGE SIZE to make sure you get all the records from your account (both public and draft)\n",
    "\n",
    "#Gather basic metadata for items (articles) that meet your search criteria\n",
    "\n",
    "query = '{\"search_for\":\"\", \"institution\":' + INST_ID + ', \"page_size\":100}' #Set up string\n",
    "y = json.loads(query) #Convert the string to a dictionary (JSON)\n",
    "y['search_for'] = ':author: \\\"'+ name + '\\\"' #This add in the name you are searching for in quotes for an exact match\n",
    "\n",
    "#y = json.loads(query) #Figshare API requires json paramaters\n",
    "r=requests.post(BASE_URL + \"/articles/search\", params=y)\n",
    "articles = json.loads(r.text) \n",
    "\n",
    "if r.status_code != 200:\n",
    "    print('Something is wrong:',r.content)\n",
    "else:\n",
    "    print('Collected',len(articles),'metadata records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe from the JSON formatted data\n",
    "dfbasic = pd.DataFrame(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-closing",
   "metadata": {},
   "source": [
    "## Or, Retrieve Metadata by ORCID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-alarm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#author name\n",
    "orcid = \"ENTER ORCID BETWEEN QUOTES\"\n",
    "\n",
    "\n",
    "\n",
    "#Institution id\n",
    "#INST_ID = \"ENTER ID HERE BETWEEN QUOTES\" #Example INST_ID = \"658\"\n",
    "INST_ID = \"ENTER ID HERE BETWEEN QUOTES\" #Example INST_ID = \"658\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve list of private metadata- this is for unpublished and published records.\n",
    "#SET THE PAGE SIZE to make sure you get all the records from your account (both public and draft)\n",
    "\n",
    "#Gather basic metadata for items (articles) that meet your search criteria\n",
    "\n",
    "query = '{\"search_for\":\":orcid:' + orcid + '\", \"institution\":' + INST_ID + ', \"page_size\":100}' #Set up string\n",
    "y = json.loads(query) #Convert the string to a dictionary (JSON)\n",
    "y['search_for'] = ':author: \\\":orcid'+ name + '\\\"' #This add in the name you are searching for in quotes for an exact match\n",
    "\n",
    "#y = json.loads(query) #Figshare API requires json paramaters\n",
    "r=requests.post(BASE_URL + \"/articles/search\", params=y)\n",
    "articles = json.loads(r.text) \n",
    "\n",
    "if r.status_code != 200:\n",
    "    print('Something is wrong:',r.content)\n",
    "else:\n",
    "    print('Collected',len(articles),'metadata records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe from the JSON formatted data\n",
    "dfbasic = pd.DataFrame(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-official",
   "metadata": {},
   "source": [
    "## Collect stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac45c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a csv file, use an API to gather data, reopen the csv as a dataframe\n",
    "\n",
    "\n",
    "#Create a list of all the article ids\n",
    "article_ids = [item['id'] for item in articles]    \n",
    "\n",
    "#Create csv file\n",
    "metadata=open('article-stats'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv', 'w', newline='')\n",
    "#Write header row to csv\n",
    "csv.writer(metadata).writerow(['id','views','downloads'])            \n",
    "\n",
    "            \n",
    "for l in article_ids:\n",
    "    s=requests.get('https://stats.figshare.com/total/views/article/'+ str(l))\n",
    "    r=json.loads(s.text)\n",
    "    t=requests.get('https://stats.figshare.com/total/downloads/article/'+ str(l))\n",
    "    q=json.loads(t.text)\n",
    "    \n",
    "    #write the values to the csv file. Dates in json files are seconds from jan 1 1970 so datetime.datetime.fromtimestamp converts\n",
    "    csv.writer(metadata).writerow([\n",
    "        l,\n",
    "        r.get('totals'), #For any of these .get(), adding \",'N/A'\" will fill the null cells with 'N/A'. However, metadata assessment counts non nulls\n",
    "        q.get('totals')]) \n",
    "    \n",
    "    \n",
    "metadata.close() #Close the output file, release all locks\n",
    "\n",
    "#Open up the same file as a dataframe. Encode cp1252 avoids a utf8 error.\n",
    "dfstats = pd.read_csv('article-stats'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv',encoding='utf8')\n",
    "\n",
    "print('The resulting dataframe has',len(dfstats),'rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-binary",
   "metadata": {},
   "source": [
    "### Merge the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmerged = dfbasic.merge(dfstats, how='inner', on='id')\n",
    "dfmerged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-screen",
   "metadata": {},
   "source": [
    "### If you have Collections run this next cell. Otherwise skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve list of private metadata- this is for unpublished and published records.\n",
    "#SET THE PAGE SIZE to make sure you get all the records\n",
    "\n",
    "#Get collections\n",
    "query = '{\"search_for\":\"\", \"institution\":' + INST_ID + ', \"page_size\":100}' #Set up string\n",
    "y = json.loads(query) #Convert the string to a dictionary (JSON)\n",
    "y['search_for'] = ':author: \\\"'+ name + '\\\"' #Add in the name you are searcing for in quotes for an exact match\n",
    "\n",
    "#y = json.loads(query) #Figshare API requires json paramaters\n",
    "r=requests.post(BASE_URL + \"/collections/search\", params=y)\n",
    "collections = json.loads(r.text)\n",
    "\n",
    "#Create a dataframe from the JSON formatted data\n",
    "dfcollbasic = pd.DataFrame(collections)\n",
    "\n",
    "#Gather Stats\n",
    "#Create a list of all the article ids\n",
    "coll_ids = [item['id'] for item in collections]    \n",
    "\n",
    "#Create csv file\n",
    "metadata=open('collection-stats'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv', 'w', newline='')\n",
    "#Write header row to csv\n",
    "csv.writer(metadata).writerow(['id','views','downloads'])            \n",
    "\n",
    "            \n",
    "for l in coll_ids:\n",
    "    s=requests.get('https://stats.figshare.com/total/views/article/'+ str(l))\n",
    "    r=json.loads(s.text)\n",
    "    t=requests.get('https://stats.figshare.com/total/downloads/article/'+ str(l))\n",
    "    q=json.loads(t.text)\n",
    "    \n",
    "    #write the values to the csv file. Dates in json files are seconds from jan 1 1970 so datetime.datetime.fromtimestamp converts\n",
    "    csv.writer(metadata).writerow([\n",
    "        l,\n",
    "        r.get('totals'), #For any of these .get(), adding \",'N/A'\" will fill the null cells with 'N/A'. However, metadata assessment counts non nulls\n",
    "        q.get('totals')]) \n",
    "    \n",
    "    \n",
    "metadata.close() #Close the output file, release all locks\n",
    "\n",
    "#Open up the same file as a dataframe. Encode cp1252 avoids a utf8 error.\n",
    "dfcollstats = pd.read_csv('collection-stats'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv',encoding='utf8')\n",
    "\n",
    "dfcollmerged = dfcollbasic.merge(dfcollstats, how='inner', on='id')\n",
    "\n",
    "#Append the collections rows to the article dataframe\n",
    "dfmerged = dfmerged.append(dfcollmerged)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-recipient",
   "metadata": {},
   "source": [
    "### Format the dates column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-preliminary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The dates are all contained within one column called 'timeline'. \n",
    "#Use the JSON to create a better format and then merge with the dataframe\n",
    "#with the proper article id in a new dataframe\n",
    "\n",
    "temp_date_list = []\n",
    "\n",
    "for item in articles:\n",
    "    dateitem = item['timeline']\n",
    "    dateitem['id'] = item['id']\n",
    "    temp_date_list.append(dateitem)\n",
    "\n",
    "df_dates_items = pd.json_normalize(\n",
    "    temp_date_list \n",
    ")\n",
    "\n",
    "\n",
    "#Have to use 'try' here just in case you ran the Collection cell above\n",
    "try:\n",
    "    #Get a dates dataframe\n",
    "    temp_coll_date_list = []\n",
    "\n",
    "    for item in collections:\n",
    "        dateitem = item['timeline']\n",
    "        dateitem['id'] = item['id']\n",
    "        temp_coll_date_list.append(dateitem)\n",
    "\n",
    "    df_coll_dates_coll = pd.json_normalize(\n",
    "        temp_coll_date_list \n",
    "    )\n",
    "# catch when published_coll_records is None\n",
    "except AttributeError:\n",
    "    pass\n",
    "# catch when it hasn't even been defined\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "\n",
    "#Append the dataframes (if collections have been found)\n",
    "try:\n",
    "    #Append the dates dataframes\n",
    "    df_dates = df_dates_items.append(df_dates_coll)\n",
    "# catch when df_dates_coll is None\n",
    "except AttributeError:\n",
    "    df_dates = df_dates_items\n",
    "# catch when it hasn't even been defined\n",
    "except NameError:\n",
    "    df_dates = df_dates_items\n",
    "    \n",
    "#Merge the date dataframe with the metadata dataframe\n",
    "df_formatted = dfmerged.merge(df_dates, how='outer', on='id')\n",
    "\n",
    "print(\"Dates split out and merged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-means",
   "metadata": {},
   "source": [
    "### View Totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#See your summarized stats\n",
    "print('Total views =', df_formatted['views'].sum(),'and total downloads =',df_formatted['downloads'].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-adoption",
   "metadata": {},
   "source": [
    "# Save the spreadsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-pakistan",
   "metadata": {},
   "source": [
    "## If you are running this in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When you run this cell it will ask you to authenticate so that you can create files to download\n",
    "from google.colab import drive\n",
    "drive.mount('/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "df_formatted.to_csv(str(name) + '-published_records-'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv',encoding='utf-8') #create the CSV\n",
    "files.download(str(name) + '-published_records-'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv') #download to your computer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-protein",
   "metadata": {},
   "source": [
    "## If you are running this locally\n",
    "That is you downloaded the Jupyter Notebook file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save a CSV file of all the metadata. Change the file name if necessary to match dates.\n",
    "save_file = df_formatted.to_csv(str(name) + '-published_records-'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or save an Excel file of all the metadata. Change the file name if necessary to match dates.\n",
    "save_file = df_formatted.to_excel(str(name) + '-published_records-'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIONAL: save the json.\n",
    "with open(str(name) + 'published_records-'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.json', 'w') as f:\n",
    "    json.dump(published_records, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
