{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "thorough-dictionary",
   "metadata": {},
   "source": [
    "## This retrieves all metadata and statistics for an account - items and collections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-williams",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e37a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-lending",
   "metadata": {},
   "source": [
    "## Set token and base URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "continued-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the token in the header.\n",
    "\n",
    "api_call_headers = {'Authorization': 'token ENTER TOKEN'} #example: {'Authorization': 'token dkd8rskjdkfiwi49hgkw...'}\n",
    "\n",
    "\n",
    "#Set the base URL\n",
    "BASE_URL = 'https://api.figshare.com/v2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-blowing",
   "metadata": {},
   "source": [
    "## Retrieve Metadata\n",
    "1. Get basic metadata for account\n",
    "2. Keep the id, title, and date posted\n",
    "3. Call the stats API to retrieve views and downloads for each id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve list of private metadata- this is for unpublished and published records.\n",
    "#SET THE PAGE SIZE to make sure you get all the records from your account (both public and draft)\n",
    "\n",
    "#Get items owned by account\n",
    "r=requests.get(BASE_URL + '/account/articles?page=1&page_size=50', headers=api_call_headers) \n",
    "articles=json.loads(r.text)\n",
    "\n",
    "if r.status_code != 200:\n",
    "    print('Something is wrong:',r.content)\n",
    "else:\n",
    "    print('Collected',len(articles),'metadata records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-amendment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep records that are either public or fully embargoed (i.e. remove drafts)\n",
    "published_records = []\n",
    "for item in articles:\n",
    "    if item['published_date'] != None: #if a record has a published date\n",
    "           published_records.append(item)\n",
    "            \n",
    "print(len(published_records), \"records kept,\",len(articles) - len(published_records),\"records removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe from the JSON formatted data\n",
    "dfbasic = pd.DataFrame(published_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIONAL: save the json.\n",
    "with open('published_records-'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.json', 'w') as f:\n",
    "    json.dump(published_records, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-official",
   "metadata": {},
   "source": [
    "## Collect stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac45c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create a list of all the article ids\n",
    "article_ids = [item['id'] for item in published_records]    \n",
    "\n",
    "#Create csv file\n",
    "metadata=open('article-stats'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv', 'w', newline='')\n",
    "#Write header row to csv\n",
    "csv.writer(metadata).writerow(['id','views','downloads'])            \n",
    "\n",
    "            \n",
    "for l in article_ids:\n",
    "    s=requests.get('https://stats.figshare.com/total/views/article/'+ str(l))\n",
    "    r=json.loads(s.text)\n",
    "    t=requests.get('https://stats.figshare.com/total/downloads/article/'+ str(l))\n",
    "    q=json.loads(t.text)\n",
    "    \n",
    "    #write the values to the csv file. Dates in json files are seconds from jan 1 1970 so datetime.datetime.fromtimestamp converts\n",
    "    csv.writer(metadata).writerow([\n",
    "        l,\n",
    "        r.get('totals'), #For any of these .get(), adding \",'N/A'\" will fill the null cells with 'N/A'. However, metadata assessment counts non nulls\n",
    "        q.get('totals')]) \n",
    "    \n",
    "    \n",
    "metadata.close() #Close the output file, release all locks\n",
    "\n",
    "#Open up the same file as a dataframe. Encode cp1252 avoids a utf8 error.\n",
    "dfstats = pd.read_csv('article-stats'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv',encoding='utf8')\n",
    "\n",
    "print('The resulting dataframe has',len(dfstats),'rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-binary",
   "metadata": {},
   "source": [
    "### Merge the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmerged = dfbasic.merge(dfstats, how='inner', on='id')\n",
    "dfmerged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-screen",
   "metadata": {},
   "source": [
    "### If you have Collections run this next cell. Otherwise skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve list of private metadata- this is for unpublished and published records.\n",
    "#SET THE PAGE SIZE to make sure you get all the records from your account (both public and draft)\n",
    "\n",
    "#Get items owned by account\n",
    "r=requests.get(BASE_URL + '/account/collections?page=1&page_size=50', headers=api_call_headers) \n",
    "collections=json.loads(r.text)\n",
    "\n",
    "#Keep records that are either public or fully embargoed (i.e. remove drafts)\n",
    "published_coll_records = []\n",
    "for item in collections:\n",
    "    if item['published_date'] != None: #if a record has a published date\n",
    "           published_coll_records.append(item)\n",
    "\n",
    "#Create a dataframe from the JSON formatted data\n",
    "dfcollbasic = pd.DataFrame(published_coll_records)\n",
    "\n",
    "#Gather Stats\n",
    "#Create a list of all the article ids\n",
    "coll_ids = [item['id'] for item in published_coll_records]    \n",
    "\n",
    "#Create csv file\n",
    "metadata=open('collection-stats'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv', 'w', newline='')\n",
    "#Write header row to csv\n",
    "csv.writer(metadata).writerow(['id','views','downloads'])            \n",
    "\n",
    "            \n",
    "for l in coll_ids:\n",
    "    s=requests.get('https://stats.figshare.com/total/views/article/'+ str(l))\n",
    "    r=json.loads(s.text)\n",
    "    t=requests.get('https://stats.figshare.com/total/downloads/article/'+ str(l))\n",
    "    q=json.loads(t.text)\n",
    "    \n",
    "    #write the values to the csv file. Dates in json files are seconds from jan 1 1970 so datetime.datetime.fromtimestamp converts\n",
    "    csv.writer(metadata).writerow([\n",
    "        l,\n",
    "        r.get('totals'), #For any of these .get(), adding \",'N/A'\" will fill the null cells with 'N/A'. However, metadata assessment counts non nulls\n",
    "        q.get('totals')]) \n",
    "    \n",
    "    \n",
    "metadata.close() #Close the output file, release all locks\n",
    "\n",
    "#Open up the same file as a dataframe. Encode cp1252 avoids a utf8 error.\n",
    "dfcollstats = pd.read_csv('collection-stats'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv',encoding='utf8')\n",
    "\n",
    "dfcollmerged = dfcollbasic.merge(dfcollstats, how='inner', on='id')\n",
    "\n",
    "#Append the collections rows to the article dataframe\n",
    "dfmerged = dfmerged.append(dfcollmerged)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-recipient",
   "metadata": {},
   "source": [
    "### Format the dates colum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-preliminary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The dates are all contained within one column called 'timeline'. \n",
    "#Use the JSON to create a better format and then merge with the dataframe\n",
    "#with the proper article id in a new dataframe\n",
    "\n",
    "temp_date_list = []\n",
    "\n",
    "for item in published_records:\n",
    "    dateitem = item['timeline']\n",
    "    dateitem['id'] = item['id']\n",
    "    temp_date_list.append(dateitem)\n",
    "\n",
    "df_dates_items = pd.json_normalize(\n",
    "    temp_date_list \n",
    ")\n",
    "\n",
    "\n",
    "#Have to use 'try' here just in case you ran the Collection cell above\n",
    "try:\n",
    "    #Get a dates dataframe\n",
    "    temp_coll_date_list = []\n",
    "\n",
    "    for item in published_coll_records:\n",
    "        dateitem = item['timeline']\n",
    "        dateitem['id'] = item['id']\n",
    "        temp_coll_date_list.append(dateitem)\n",
    "\n",
    "    df_coll_dates_coll = pd.json_normalize(\n",
    "        temp_coll_date_list \n",
    "    )\n",
    "# catch when published_coll_records is None\n",
    "except AttributeError:\n",
    "    pass\n",
    "# catch when it hasn't even been defined\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "\n",
    "#Append the dataframes (if collections have been found)\n",
    "try:\n",
    "    #Append the dates dataframes\n",
    "    df_dates = df_dates_items.append(df_dates_coll)\n",
    "# catch when df_dates_coll is None\n",
    "except AttributeError:\n",
    "    df_dates = df_dates_items\n",
    "# catch when it hasn't even been defined\n",
    "except NameError:\n",
    "    df_dates = df_dates_items\n",
    "    \n",
    "#Merge the date dataframe with the metadata dataframe\n",
    "df_formatted = dfmerged.merge(df_dates, how='outer', on='id')\n",
    "\n",
    "print(\"Dates split out and merged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-means",
   "metadata": {},
   "source": [
    "### View Totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#See your summarized stats\n",
    "print('Total views =', df_formatted['views'].sum(),'and total downloads=',df_formatted['downloads'].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-adoption",
   "metadata": {},
   "source": [
    "## Save the spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save a CSV file of all the metadata. Change the file name if necessary to match dates.\n",
    "save_file = df_formatted.to_csv('my-records-'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or save an Excel file of all the metadata. Change the file name if necessary to match dates.\n",
    "save_file = df_formatted.to_excel('my-records-'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
